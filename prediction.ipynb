{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell001.dat -> 577 time steps\n",
      "cell002.dat -> 577 time steps\n",
      "cell003.dat -> 577 time steps\n",
      "cell004.dat -> 577 time steps\n",
      "cell005.dat -> 577 time steps\n",
      "cell006.dat -> 577 time steps\n",
      "cell007.dat -> 577 time steps\n",
      "cell008.dat -> 577 time steps\n",
      "cell009.dat -> 577 time steps\n",
      "cell010.dat -> 577 time steps\n",
      "cell011.dat -> 577 time steps\n",
      "cell012.dat -> 577 time steps\n",
      "cell013.dat -> 577 time steps\n",
      "cell014.dat -> 577 time steps\n",
      "cell015.dat -> 577 time steps\n",
      "cell016.dat -> 577 time steps\n",
      "cell017.dat -> 577 time steps\n",
      "cell018.dat -> 577 time steps\n",
      "cell019.dat -> 577 time steps\n",
      "cell020.dat -> 577 time steps\n",
      "cell021.dat -> 577 time steps\n",
      "cell022.dat -> 577 time steps\n",
      "cell023.dat -> 577 time steps\n",
      "cell024.dat -> 577 time steps\n",
      "cell025.dat -> 577 time steps\n",
      "cell026.dat -> 577 time steps\n",
      "cell027.dat -> 577 time steps\n",
      "cell028.dat -> 577 time steps\n",
      "cell029.dat -> 577 time steps\n",
      "cell030.dat -> 577 time steps\n",
      "cell031.dat -> 577 time steps\n",
      "cell032.dat -> 577 time steps\n",
      "cell033.dat -> 577 time steps\n",
      "cell034.dat -> 577 time steps\n",
      "cell035.dat -> 577 time steps\n",
      "cell036.dat -> 577 time steps\n",
      "cell037.dat -> 577 time steps\n",
      "cell038.dat -> 577 time steps\n",
      "cell039.dat -> 577 time steps\n",
      "cell040.dat -> 577 time steps\n",
      "cell041.dat -> 577 time steps\n",
      "cell042.dat -> 577 time steps\n",
      "cell043.dat -> 577 time steps\n",
      "cell044.dat -> 577 time steps\n",
      "cell045.dat -> 577 time steps\n",
      "cell046.dat -> 577 time steps\n",
      "cell047.dat -> 577 time steps\n",
      "cell048.dat -> 577 time steps\n",
      "cell049.dat -> 577 time steps\n",
      "cell050.dat -> 577 time steps\n",
      "cell051.dat -> 577 time steps\n",
      "cell052.dat -> 577 time steps\n",
      "cell053.dat -> 577 time steps\n",
      "cell054.dat -> 577 time steps\n",
      "cell055.dat -> 577 time steps\n",
      "cell056.dat -> 577 time steps\n",
      "cell057.dat -> 577 time steps\n",
      "cell058.dat -> 577 time steps\n",
      "cell059.dat -> 577 time steps\n",
      "cell060.dat -> 577 time steps\n",
      "cell061.dat -> 577 time steps\n",
      "cell062.dat -> 577 time steps\n",
      "cell063.dat -> 577 time steps\n",
      "cell064.dat -> 577 time steps\n",
      "cell065.dat -> 577 time steps\n"
     ]
    }
   ],
   "source": [
    "# Read all data files of one category.\n",
    "import os\n",
    "data_dir = 'data/JulianTrajs/alive'\n",
    "trajectories = []  # dimensions: trajectory index -> time step -> coordinate (x, y, z)\n",
    "for filename in os.listdir(data_dir):\n",
    "    print filename, '->',\n",
    "    trajectory = np.genfromtxt(os.path.join(data_dir, filename))\n",
    "    print trajectory.shape[0], 'time steps'\n",
    "    trajectories.append(trajectory)\n",
    "trajectories = np.array(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 0.99999999999999978)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize trajectories to [-1, 1] for the LSTM network (it outputs values between -1 and 1 by default).\n",
    "# TODO: Try to change the activation in the LSTM to do this without normalization.\n",
    "min_value = np.min(trajectories)\n",
    "max_value = np.max(trajectories)\n",
    "normalized_trajectories = np.interp(trajectories, [min_value, max_value], [-1., 1.])\n",
    "np.min(normalized_trajectories), np.max(normalized_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 11895 data samples\n"
     ]
    }
   ],
   "source": [
    "# TODO: Split into training/test data here.\n",
    "# TODO: Possible to use validation data in this scenario?\n",
    "\n",
    "\n",
    "# Split trajectories into short parts following. Save the next position for each part.\n",
    "# See also https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "maxlen = 30  # Change this to see how strong the current position depends on the positions long ago. REPHRASE THIS\n",
    "step = 3  # Change this to vary redundancy. \n",
    "mini_trajectories = []\n",
    "next_position = []\n",
    "\n",
    "for trajectory in normalized_trajectories:\n",
    "    for i in range(0, len(trajectory) - maxlen, step):\n",
    "        mini_trajectories.append(trajectory[i:i+maxlen] - trajectory[i])  # Set start of mini trajectory to origin.\n",
    "        next_position.append(trajectory[i+maxlen] - trajectory[i])\n",
    "        \n",
    "mini_trajectories = np.array(mini_trajectories)\n",
    "next_position = np.array(next_position)\n",
    "\n",
    "print 'Created', len(mini_trajectories), 'data samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  4.24492619e-04,   2.56073140e-03,  -2.37195457e-03],\n",
       "        [ -1.68487032e-02,   1.01107443e-02,  -2.81380391e-02],\n",
       "        [ -1.67329952e-02,   1.17608261e-02,  -3.08212290e-02],\n",
       "        [ -1.64276682e-02,   1.33972310e-02,  -3.33201151e-02],\n",
       "        [ -1.58370445e-02,   1.53353374e-02,  -3.55339757e-02],\n",
       "        [ -1.59937246e-02,   1.72160326e-02,  -3.28037968e-02],\n",
       "        [ -1.63432447e-02,   1.86186856e-02,  -3.02652019e-02],\n",
       "        [ -1.69490340e-02,   1.40433043e-02,  -3.36840768e-02],\n",
       "        [ -1.71294628e-02,   5.40068532e-03,  -3.09719317e-02],\n",
       "        [ -1.73330169e-02,   1.24444121e-02,  -3.96804076e-02],\n",
       "        [ -1.75800561e-02,   8.02492167e-03,  -3.70387614e-02],\n",
       "        [ -1.77364841e-02,   3.78263155e-03,  -3.43101702e-02],\n",
       "        [ -1.75452827e-02,   8.71009264e-05,  -3.69304504e-02],\n",
       "        [ -1.70209069e-02,   1.93610048e-03,  -3.35148921e-02],\n",
       "        [ -1.19667656e-02,   8.93633482e-03,  -3.12728535e-02],\n",
       "        [ -1.23402583e-02,   9.99011784e-03,  -3.44548159e-02],\n",
       "        [ -1.27533686e-02,   5.80586998e-03,  -3.19832776e-02],\n",
       "        [ -1.81757797e-02,  -2.97714065e-03,  -2.88232043e-02],\n",
       "        [ -1.29995014e-02,  -1.73168653e-03,  -3.78548246e-02],\n",
       "        [ -1.31991482e-02,  -5.63947675e-03,  -4.08606820e-02],\n",
       "        [ -1.93580671e-02,  -1.43181225e-02,  -3.84210489e-02],\n",
       "        [ -2.47010641e-02,  -1.81473405e-02,  -3.51717319e-02],\n",
       "        [ -2.54131862e-02,  -2.20322507e-02,  -3.29952461e-02],\n",
       "        [ -2.61315882e-02,  -2.02548342e-02,  -3.65229510e-02],\n",
       "        [ -3.14283258e-02,  -2.45087890e-02,  -3.32340974e-02],\n",
       "        [ -3.18170098e-02,  -3.41662464e-02,  -3.07351450e-02],\n",
       "        [ -3.19969680e-02,  -3.23159722e-02,  -3.37218314e-02],\n",
       "        [ -3.64393578e-02,  -4.59276967e-02,  -3.52629299e-02],\n",
       "        [ -3.63424871e-02,  -5.40262847e-02,  -3.79615171e-02]]),\n",
       " array([-0.0360873 , -0.04684932, -0.03482162]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_trajectories[0], next_position[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: Try stateful for the same trajectory\n",
    "# TODO: Play around with output_dim here. \n",
    "model.add(LSTM(input_shape=(maxlen, 3), output_dim=30, return_sequences=True))  # TODO: Is it possible to use input_dim here and omit maxlen?\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(LSTM(output_dim=3, return_sequences=False))\n",
    "# TODO: Add Dropout and more LSTM layers. \n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11895/11895 [==============================] - 10s - loss: 0.0012    \n",
      "Epoch 2/5\n",
      "11895/11895 [==============================] - 10s - loss: 6.8274e-04    \n",
      "Epoch 3/5\n",
      "11895/11895 [==============================] - 10s - loss: 5.1614e-04    \n",
      "Epoch 4/5\n",
      "11895/11895 [==============================] - 10s - loss: 4.3312e-04    \n",
      "Epoch 5/5\n",
      "11895/11895 [==============================] - 10s - loss: 3.7538e-04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x305476b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model.\n",
    "\n",
    "model.fit(mini_trajectories, next_position, nb_epoch=5, verbose=1)\n",
    "\n",
    "# TODO: See if GPU is better for RNN (according to keras docs)\n",
    "# TODO: Play with batch_size\n",
    "# TODO: Other implementation: learn on single trajectory, X = trajectory[:-1], y = trajectory[1:], then repeat this for the other trajectories\n",
    "# Input and output dimension 3 in this case; does the network have to be stateful?\n",
    "# TODO: maybe try displacement instead of absolute position\n",
    "\n",
    "# TODO: How is the accuracy calculated here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the model predictions on the training data. \n",
    "predicted = np.interp(model.predict(mini_trajectories), [-1., 1.], [min_value, max_value])\n",
    "expected = np.interp(next_position, [-1., 1.], [min_value, max_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ -0.47713725, -19.10751164, -18.02807261]),\n",
       "  array([-10.096139 , -22.542305 , -25.0102487])),\n",
       " (array([ -2.73636023, -14.29024984, -26.91371666]),\n",
       "  array([-18.307054 , -13.028345 , -33.2387054])),\n",
       " (array([-21.20935885, -23.8794894 , -25.49224121]),\n",
       "  array([-24.246379 , -24.169965 , -36.6110255])),\n",
       " (array([-33.56979826, -28.32594549, -15.08789061]),\n",
       "  array([-27.113701 , -21.297455 , -24.0159445])),\n",
       " (array([-29.4982831 , -20.36990889, -30.71483103]),\n",
       "  array([-28.992832 , -16.029745 , -38.8122592])),\n",
       " (array([-27.27163613, -23.38424054, -24.43288685]),\n",
       "  array([-15.703803 , -21.754745 , -30.6932721])),\n",
       " (array([-17.68826709, -26.43776746, -20.81371312]),\n",
       "  array([ -8.35351  , -23.251935 , -18.1609388])),\n",
       " (array([-12.7457865 , -25.79536684, -20.97290209]),\n",
       "  array([ -6.066881 , -22.020575 , -23.6133998])),\n",
       " (array([-12.02653754, -26.59642647, -19.6631983 ]),\n",
       "  array([ -6.510496  , -20.746625  , -18.89604563])),\n",
       " (array([-13.95560003, -27.10990917, -16.51699824]),\n",
       "  array([ -9.364848  , -20.925835  , -16.57628471])),\n",
       " (array([-11.06416111, -24.14090163, -17.71440584]),\n",
       "  array([ -8.395008 , -18.440195 , -15.5974316])),\n",
       " (array([ -8.46467625, -25.8629663 , -16.72867518]),\n",
       "  array([ -3.336677  , -25.376125  , -18.24438694])),\n",
       " (array([-12.5570319 , -27.62591679, -14.33481909]),\n",
       "  array([ -6.612074 , -27.885975 , -18.9164164])),\n",
       " (array([-11.28324939, -28.52442083, -14.1065472 ]),\n",
       "  array([ -7.037387  , -28.790315  , -16.73357293])),\n",
       " (array([-10.04954682, -26.5615885 , -17.14972114]),\n",
       "  array([ -6.24462  , -23.718345 , -18.4900409])),\n",
       " (array([-20.28444991, -26.78440776, -15.43118669]),\n",
       "  array([-15.516967 , -20.554275 , -22.5880186])),\n",
       " (array([-15.54972254, -25.91113219, -20.1460892 ]),\n",
       "  array([ -9.031575 , -24.084565 , -29.0217977])),\n",
       " (array([-17.31440535, -28.43641605, -15.89206627]),\n",
       "  array([ -8.044022 , -22.120965 , -20.3191044])),\n",
       " (array([-13.98335754, -28.61962754, -18.45269264]),\n",
       "  array([ -9.775819  , -24.829105  , -29.78608607])),\n",
       " (array([ -9.11051366, -26.94361359, -19.29054915]),\n",
       "  array([ -6.083484  , -24.699615  , -28.67121589]))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(predicted[100:120], expected[100:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8543555095444537"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rough measure for deviation. 7.715\n",
    "np.sum(np.abs(predicted - expected)) / len(predicted) / 3.\n",
    "# TODO: Compare with constant or random predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.406808847973547"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(expected)) / len(expected) / 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,    0.        ,    0.        ],\n",
       "       [   0.19224073,    1.159683  ,   -1.0741913 ],\n",
       "       [  -7.6303023 ,    4.5788708 ,  -12.742924  ],\n",
       "       ..., \n",
       "       [ 169.71178   , -139.37348   ,   -6.4971753 ],\n",
       "       [ 170.10865   , -140.88685   ,   -4.7908792 ],\n",
       "       [ 172.87403   , -140.08097   ,   -5.8794939 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Other possible idea: Make matrix around current position with probabilities as output\n",
    "# TODO: CLassification: feed in points step by step, see how classification probability changes\n",
    "# TODO: Make the network predict persistence etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8173631071746126"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constant predictor (take last position of trajectory as prediction for next position).\n",
    "last_positions = mini_trajectories[:, -1]\n",
    "constant_predicted = np.interp(last_positions, [-1., 1.], [min_value, max_value])\n",
    "np.sum(np.abs(constant_predicted - expected)) / len(predicted) / 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:15:38.444000",
     "start_time": "2016-03-30T17:15:38.044000"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:15:41.218000",
     "start_time": "2016-03-30T17:15:39.460000"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category alive: Found 65 files, created 65 trajectories\n",
      "Category fibro: Found 69 files, created 69 trajectories\n",
      "Category plastic: Found 177 files, created 177 trajectories\n"
     ]
    }
   ],
   "source": [
    "# Read all data files of all categories.\n",
    "import os\n",
    "\n",
    "trajectories_per_category = {}\n",
    "categories = ['alive', 'fibro', 'plastic']\n",
    "downsample_steps = {'alive': 2, 'fibro': 5, 'plastic': 5}  # TODO: Rename var.\n",
    "\n",
    "for category in categories:\n",
    "    data_dir = 'data/JulianTrajs/' + category\n",
    "    trajectories_per_category[category] = []  # dimensions: trajectory index -> time step -> coordinate (x, y, z)\n",
    "    filenames = os.listdir(data_dir)\n",
    "    for filename in filenames:\n",
    "        trajectory = np.genfromtxt(os.path.join(data_dir, filename))\n",
    "#         for start in range(1):#downsample_steps[category]):\n",
    "#             end = -(downsample_steps[category] - start)\n",
    "#             sliced_trajectory = trajectory[start:end:downsample_steps[category]]\n",
    "        trajectories_per_category[category].append(trajectory[::downsample_steps[category]])\n",
    "    trajectories_per_category[category] = np.array(trajectories_per_category[category])\n",
    "    print \"Category {}: Found {} files, created {} trajectories\".format(category, len(filenames), len(trajectories_per_category[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:15:46.620000",
     "start_time": "2016-03-30T17:15:46.618000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_trajectories_per_category, test_ctrajectories_per_category = split(tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:15:49.219000",
     "start_time": "2016-03-30T17:15:49.213000"
    },
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert to velocities (um / min).\n",
    "for category in trajectories_per_category:\n",
    "    trajectories_per_category[category] = np.diff(trajectories_per_category[category], axis=1) / 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:15:52.034000",
     "start_time": "2016-03-30T17:15:52.023000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize trajectories to [-1, 1] for the LSTM network (it outputs values between -1 and 1 by default).\n",
    "min_value = np.min([np.min(traj) for traj in trajectories_per_category.values()])\n",
    "max_value = np.max([np.max(traj) for traj in trajectories_per_category.values()])\n",
    "for category in trajectories_per_category:\n",
    "    trajectories_per_category[category] = np.interp(trajectories_per_category[category], [min_value, max_value], [-1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-29T14:53:25.687000",
     "start_time": "2016-03-29T14:53:25.685000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Split the original trajectories into training/test so we can use the same split for mini trajectories of different sizes.\n",
    "# TODO: Use seed when shuffling so we always get the same training/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:16:01.166000",
     "start_time": "2016-03-30T17:16:01.162000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_together(*args):\n",
    "    rng_state = np.random.get_state()\n",
    "    for arg in args:\n",
    "        np.random.shuffle(arg)\n",
    "        np.random.set_state(rng_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:16:01.674000",
     "start_time": "2016-03-30T17:16:01.670000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split(arr, fraction):\n",
    "    index_to_split = int(np.rint(fraction * len(arr)))\n",
    "    return arr[:index_to_split], arr[index_to_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:16:03.711000",
     "start_time": "2016-03-30T17:16:03.559000"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2484 mini trajectories for fibro\n",
      "Created 3510 mini trajectories for alive\n",
      "Created 6372 mini trajectories for plastic\n",
      "Total: 12366 mini trajectories\n"
     ]
    }
   ],
   "source": [
    "len_mini_trajectories = 20\n",
    "step = 5\n",
    "\n",
    "mini_trajectories_per_category = {}\n",
    "category_to_target = {'alive': 0, 'fibro': 1, 'plastic': 2}\n",
    "target_to_category = {0: 'alive', 1: 'fibro', 2: 'plastic'}\n",
    "\n",
    "for category in trajectories_per_category:\n",
    "    \n",
    "    mini_trajectories_per_category[category] = []\n",
    "    \n",
    "    for trajectory in trajectories_per_category[category]:\n",
    "        for i in range(0, len(trajectory) - len_mini_trajectories, step):\n",
    "            mini_trajectories_per_category[category].append(trajectory[i:i+len_mini_trajectories])\n",
    "            \n",
    "    print 'Created {} mini trajectories for {}'.format(len(mini_trajectories_per_category[category]), category)\n",
    "    \n",
    "# Take the same number of trajectories per category so we train equal on all categories.\n",
    "#num_mini_trajectories_per_category = np.min([len(arr) for arr in mini_trajectories_per_category.values()])\n",
    "\n",
    "mini_trajectories = []\n",
    "classes = []\n",
    "class_weights = {}\n",
    "for category, mini_traj in mini_trajectories_per_category.items():\n",
    "    np.random.shuffle(mini_traj)\n",
    "    mini_trajectories.extend(mini_traj)#[:num_mini_trajectories_per_category])\n",
    "    classes.extend([category_to_target[category]] * len(mini_traj))#num_mini_trajectories_per_category)\n",
    "    class_weights[category_to_target[category]] = 1. / len(mini_traj)\n",
    "\n",
    "mini_trajectories = np.array(mini_trajectories)\n",
    "classes = np.array(classes)\n",
    "from keras.utils import np_utils\n",
    "targets = np_utils.to_categorical(classes, 3)\n",
    "\n",
    "shuffle_together(mini_trajectories, classes, targets)\n",
    "\n",
    "#print 'Taking {} mini trajectories for each category --> Total: {}'.format(num_mini_trajectories_per_category, len(mini_trajectories))  \n",
    "print 'Total: {} mini trajectories'.format(len(mini_trajectories))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:16:05.618000",
     "start_time": "2016-03-30T17:16:05.614000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0002849002849002849,\n",
       " 1: 0.00040257648953301127,\n",
       " 2: 0.00015693659761456373}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:16:19.850000",
     "start_time": "2016-03-30T17:16:19.846000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Split validation dataset here and pass it to fit function via validation_data parameter.\n",
    "test_mini_trajectories, training_mini_trajectories = split(mini_trajectories, 0.2)\n",
    "test_classes, training_classes = split(classes, 0.2)\n",
    "test_targets, training_targets = split(targets, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:17:39.970000",
     "start_time": "2016-03-30T17:16:23.472000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "D:\\Python\\27_32bit\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Set up the network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: Train with different number of LSTM layers and LSTM layer sizes and compare accuracy.\n",
    "model.add(LSTM(input_dim=3, output_dim=10, return_sequences=True))\n",
    "#model.add(LSTM(output_dim=10, return_sequences=True))\n",
    "model.add(LSTM(output_dim=10, return_sequences=False))\n",
    "model.add(Dense(output_dim=3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-30T17:17:39.983000",
     "start_time": "2016-03-30T17:17:39.972000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Callback to evaluate accuracy for each class during training. \n",
    "from keras.callbacks import Callback\n",
    "class ClassHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.class_acc = [[], [], []]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        training_predicted = self.model.predict_classes(training_mini_trajectories, verbose=0)\n",
    "        for which_class in [0, 1, 2]:\n",
    "            training_acc = 1. * np.sum(training_predicted[training_classes == which_class] == which_class) / len(training_predicted[training_classes == which_class])\n",
    "            self.class_acc[which_class].append(training_acc)\n",
    "            \n",
    "classHistory = ClassHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-03-30T15:16:45.421Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-03-30T15:17:18.736Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9893 samples, validate on 2473 samples\n",
      "Epoch 1/100\n",
      "9893/9893 [==============================] - 19s - loss: 1.0190 - acc: 0.5170 - val_loss: 0.9961 - val_acc: 0.5334\n",
      "Epoch 2/100\n",
      "9893/9893 [==============================] - 20s - loss: 0.9988 - acc: 0.5231 - val_loss: 0.9934 - val_acc: 0.5253\n",
      "Epoch 3/100\n",
      "9893/9893 [==============================] - 18s - loss: 0.9920 - acc: 0.5276 - val_loss: 0.9934 - val_acc: 0.5192\n",
      "Epoch 4/100\n",
      "2955/9893 [=======>......................] - ETA: 10s - loss: 0.9953 - acc: 0.5137"
     ]
    }
   ],
   "source": [
    "# TODO: Play around with parameters of rmsprop.\n",
    "hist = model.fit(training_mini_trajectories, training_targets, \n",
    "                 batch_size=15, nb_epoch=100, \n",
    "                 verbose=1, show_accuracy=True, validation_data=(test_mini_trajectories, test_targets))#, callbacks=[classHistory])\n",
    "\n",
    "accs.extend(hist.history['acc'])\n",
    "val_accs.extend(hist.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-29T17:54:35.649000",
     "start_time": "2016-03-29T17:54:35.206000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(accs, label='Training')\n",
    "plt.plot(val_accs, label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "#plt.xlim(60, 100)\n",
    "#plt.ylim(0.9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-12T18:21:12.766000",
     "start_time": "2016-03-12T18:21:12.402000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Use only training dataset here.\n",
    "for i, class_acc in enumerate(classHistory.class_acc):\n",
    "    plt.plot(class_acc, '-', label=\"Class {}\".format(i))\n",
    "    \n",
    "#plt.ylim(0, 1)\n",
    "#plt.xlim(50, 70)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-12T18:21:37.843000",
     "start_time": "2016-03-12T18:21:37.584000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test on a random mini trajectory from the test dataset.\n",
    "i = np.random.randint(len(test_mini_trajectories))\n",
    "# TODO: Check if this is correct; most trajectories seem to go to the top right.\n",
    "reconstructed_trajectory = np.cumsum(test_mini_trajectories[i], axis=0) - test_mini_trajectories[i, 0]\n",
    "plt.plot(reconstructed_trajectory[:, 0], reconstructed_trajectory[:, 1])\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "\n",
    "probabilities, = model.predict(test_mini_trajectories[i:i+1])\n",
    "\n",
    "for cat, prob in enumerate(probabilities):    \n",
    "    print 'Class {}: {:.3f}'.format(cat, prob)    \n",
    "        \n",
    "print 'Is Class', test_classes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-29T17:05:50.392000",
     "start_time": "2016-03-29T17:05:48.314000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate accuracy for each class. \n",
    "# TODO: Compare this to human performance.\n",
    "\n",
    "# TODO: What does batch_size do in predict? Esp, is the state of the RNN preserved or reset during one batch?\n",
    "# TODO: Maybe use evaluate together with show_accuracy for some of those things here.\n",
    "training_predicted = model.predict_classes(training_mini_trajectories, verbose=0)\n",
    "test_predicted = 0#model.predict_classes(test_mini_trajectories, verbose=0)\n",
    "\n",
    "training_acc = 1. * np.sum(training_predicted == training_classes) / len(training_predicted)\n",
    "test_acc = 0#1. * np.sum(test_predicted == test_classes) / len(test_predicted)\n",
    "print 'Overall accuracy:               Training: {:.3f}, Test: {:.3f}'.format(training_acc, test_acc)\n",
    "\n",
    "for which_class in [0, 1, 2]:\n",
    "    training_acc = 1. * np.sum(training_predicted[training_classes == which_class] == which_class) / len(training_predicted[training_classes == which_class])\n",
    "    test_acc = 0#1. * np.sum(test_predicted[test_classes == which_class] == which_class) / len(test_predicted[test_classes == which_class])\n",
    "    print 'Accuracy for class {} ({:^7}): Training: {:.3f}, Test: {:.3f}'.format(which_class, target_to_category[which_class], training_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use only x and y coordinates for classification and compare to accuracy of using x/y/z data.\n",
    "# TODO: Predict trajectory of one specific class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate accuracy for trajectories of different lengths (ie with different numbers of time steps).\n",
    "# TODO: Does keras reset the state after each prediction?\n",
    "# TODO: Make this work for all classes.\n",
    "\n",
    "# According to the RBM thesis, the data should be correlated for 3 to 7 (corrected) time steps. \n",
    "# See details for each category in the thesis - can we replicate this with the NN?\n",
    "\n",
    "mini_trajectories_per_length = {}\n",
    "for length in range(2, 30):\n",
    "    mini_trajectories_per_length[length] = []\n",
    "    for trajectory in trajectories_per_category['plastic']:  # TODO: Do this for all categories/for test dataset.\n",
    "        for i in range(0, len(trajectory) - length, 5):\n",
    "            mini_trajectories_per_length[length].append(trajectory[i:i+length])  # Set start of mini trajectory to origin.\n",
    "    mini_trajectories_per_length[length] = np.array(mini_trajectories_per_length[length])\n",
    "    \n",
    "# TODO: Make plot of raw probabilities over trajectory length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "for length, traj in mini_trajectories_per_length.items():\n",
    "    a = evaluate(traj, 2)\n",
    "    print 'Accuracy for length {}: {:.3f}'.format(length, a)\n",
    "    acc.append(a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(mini_trajectories_per_length.keys(), acc, 'o-')\n",
    "plt.xlabel('Trajectory Length')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Possible parameters for future hyperparemeter optimzation:\n",
    "# - mini trajectory length\n",
    "# - mini trajectory step\n",
    "# - output_dim\n",
    "# - number of LSTM layers\n",
    "# - rmsprop parameters\n",
    "# - batch_size\n",
    "# - activation/internal parameters of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model to file.\n",
    "open('model/my_model_architecture.json', 'w').write(model.to_json())\n",
    "model.save_weights('model/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model from file.\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(open('model/my_model_architecture.json').read())\n",
    "model.load_weights('model/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
